{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCIHr8wZDtNm",
        "outputId": "21c31501-87ca-4eec-d4b3-fa8d0c4e23a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import pdfplumber\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_clean_text_chunks_from_pdf(pdf_path, chunk_size=1000):\n",
        "    text_chunks = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                page_text = re.sub(r'http\\S+|www\\S+|file:\\S+|\\S+\\.html', '', page_text)\n",
        "                page_text = re.sub(r'\\s+', ' ', page_text).strip()\n",
        "                for i in range(0, len(page_text), chunk_size):\n",
        "                    text_chunks.append(page_text[i:i + chunk_size])\n",
        "    return text_chunks\n",
        "\n",
        "question_generator = pipeline(\"text2text-generation\", model=\"valhalla/t5-small-qa-qg-hl\")\n",
        "\n",
        "def generate_questions(text, num_questions=15):\n",
        "    formatted_text = \"generate question: \" + text\n",
        "    questions = question_generator(formatted_text, max_length=100, num_beams=5, num_return_sequences=num_questions)\n",
        "    return questions\n",
        "\n",
        "def retrieve_relevant_chunks(prompt, text_chunks, top_n=5):\n",
        "    vectorizer = TfidfVectorizer().fit_transform([prompt] + text_chunks)\n",
        "    cosine_similarities = cosine_similarity(vectorizer[0:1], vectorizer[1:]).flatten()\n",
        "    top_n_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
        "    relevant_chunks = [text_chunks[i] for i in top_n_indices]\n",
        "    return relevant_chunks\n",
        "\n",
        "def generate_questions_from_prompt_with_rag(prompt, pdf_text, total_questions=20, top_n_chunks=5, questions_per_chunk=2):\n",
        "    relevant_chunks = retrieve_relevant_chunks(prompt, pdf_text, top_n=top_n_chunks)\n",
        "\n",
        "    if not relevant_chunks:\n",
        "        print(\"No relevant chunks found for the prompt.\")\n",
        "        return []\n",
        "\n",
        "    all_generated_questions = set()\n",
        "    for chunk in relevant_chunks:\n",
        "        questions = generate_questions(chunk, num_questions=questions_per_chunk)\n",
        "        for q in questions:\n",
        "            cleaned_question = re.sub(r'\\s+', ' ', q['generated_text']).strip()\n",
        "            if len(cleaned_question) > 15:\n",
        "                all_generated_questions.add(cleaned_question)\n",
        "\n",
        "        if len(all_generated_questions) >= total_questions:\n",
        "            break\n",
        "\n",
        "    return list(all_generated_questions)[:total_questions]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = input(\"Enter the PDF file path :\")\n",
        "\n",
        "    prompt = input(\"Enter a prompt (a complete sentence or a word): \")\n",
        "\n",
        "    text_chunks = extract_clean_text_chunks_from_pdf(pdf_path)\n",
        "\n",
        "    if not text_chunks:\n",
        "        print(\"No text found in the PDF.\")\n",
        "    else:\n",
        "        generated_questions = generate_questions_from_prompt_with_rag(\n",
        "            prompt, text_chunks, total_questions=20, top_n_chunks=5, questions_per_chunk=2\n",
        "        )\n",
        "\n",
        "        if not generated_questions:\n",
        "            print(\"No questions were generated. Please check the prompt or PDF content.\")\n",
        "        else:\n",
        "            output_file = \"generated_questions.txt\"\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                for idx, question in enumerate(generated_questions, 1):\n",
        "                    print(f\"{idx}. {question}\")\n",
        "                    f.write(f\"{idx}. {question}\\n\")\n",
        "\n",
        "            print(f\"Generated {len(generated_questions)} questions and saved to '{output_file}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUbblu2cD-kJ",
        "outputId": "a9ea687d-d36c-4afb-bcde-0eae1deb25a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the PDF file path :/content/KarmaYoga.pdf\n",
            "Enter a prompt (a complete sentence or a word): Sannyasin\n",
            "1. What did the Sannyasin think the Vyadha gave him?\n",
            "2. What did the Sannyasin say to the Sannyasin?\n",
            "3. What was the name of the young Sannyasin who refused to marry the princess?\n",
            "4. What did the young Sannyasin threw the garland over the Sannyasin?\n",
            "5. What did many wise men seek to solve the problem of Sannyasin?\n",
            "6. What happened to the young Sannyasin who refused to marry the princess?\n",
            "7. What did the young Sannyasin threw the garland over the princess?\n",
            "8. What was the name of the king who followed the Sannyasin out of his territory?\n",
            "9. What did many wise men seek to solve the problem of the Sannyasin?\n",
            "10. What was the name of the king who followed the Sannyasin out of his own territory?\n",
            "Generated 10 questions and saved to 'generated_questions.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_nQWpAbuEvaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}